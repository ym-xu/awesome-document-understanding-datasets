# ğŸ“š Awesome Document Understanding Datasets

This repository collects major datasets used in **Document Understanding (DU)** research, covering tasks like OCR, form understanding, table extraction, document VQA, key information extraction, and multimodal document reasoning.

We aim to provide:
- âœ… An organized list of DU datasets
- âœ… Paper references and official links
- âœ… A one-click script to download datasets locally

---

## ğŸ—‚ï¸ Dataset Categories

### ğŸ–¼ï¸ 1. OCR & Layout Analysis

| Dataset     | Description                       | Size   | Language | Paper / Link | ğŸ› ï¸ In Script? |
|-------------|-----------------------------------|--------|----------|----------------|--------|
| RVL-CDIP    | Document classification (16 types)| 400k+  | English  | [ğŸ“„](https://arxiv.org/abs/1505.03850), [ğŸ”—](https://www.cs.cmu.edu/~aharley/rvl-cdip/) |
| PubLayNet   | Layout segmentation in papers     | 360k   | English  | [ğŸ“„](https://arxiv.org/abs/1908.07836), [ğŸ”—](https://github.com/ibm-aur-nlp/PubLayNet) |
| DocBank     | Document layout annotations       | 500k+  | English  | [ğŸ“„](https://arxiv.org/abs/2006.01038), [ğŸ”—](https://github.com/doc-analysis/DocBank) |
| IIT-CDIP    | Scanned documents for OCR         | 11M+   | English  | [ğŸ”—](https://www.cs.cmu.edu/~aharley/rvl-cdip/) |

---

### ğŸ§¾ 2. Form Understanding & Key Information Extraction (KIE)

| Dataset     | Description                       | Size   | Language | Paper / Link | ğŸ› ï¸ In Script? |
|-------------|-----------------------------------|--------|----------|----------------|--------|
| FUNSD       | Form + OCR + entity linking       | 199    | English  | [ğŸ“„](https://arxiv.org/abs/1905.13538), [ğŸ”—](https://guillaumejaume.github.io/FUNSD/) |
| CORD        | Receipt KIE                       | 1,000+ | KR/EN    | [ğŸ“„](https://arxiv.org/abs/1912.03299), [ğŸ”—](https://github.com/clovaai/cord) |
| XFUND       | Multilingual form understanding   | 1,000+ | 7 langs  | [ğŸ“„](https://arxiv.org/abs/2102.08903), [ğŸ”—](https://github.com/doc-analysis/XFUND) |
| SROIE       | Invoice info extraction           | ~1,000 | English  | [ğŸ”—](https://rrc.cvc.uab.es/?ch=13) |
| Kleister-NDA   | Legal      | NDA entity extraction               | English  | [ğŸ“„](https://arxiv.org/abs/2003.04988), [ğŸ”—](https://github.com/applicaai/kleister-nda) |
---

### ğŸ“Š 3. Table Detection & Structure Recognition

| Dataset     | Description                       | Size   | Language | Paper / Link | ğŸ› ï¸ In Script? |
|-------------|-----------------------------------|--------|----------|----------------|--------|
| TableBank   | Table detection (Word/PDF)        | 417k   | EN/CH    | [ğŸ“„](https://arxiv.org/abs/1903.10676), [ğŸ”—](https://doc-analysis.github.io/tablebank-page/) |
| SciTSR      | Table structure recognition       | 12k    | English  | [ğŸ“„](https://arxiv.org/abs/1911.04994), [ğŸ”—](https://github.com/abc-nlp/SciTSR) |
| SciCap      | Table caption generation          | 12k    | English  | [ğŸ“„](https://arxiv.org/abs/2010.03150), [ğŸ”—](https://github.com/lichengunc/SciCap) |

---

### â“ 4. Document Visual Question Answering (DocVQA)

| Dataset     | Description                       | Size   | Language | Paper / Link | ğŸ› ï¸ In Script? |
|-------------|-----------------------------------|--------|----------|----------------|--------|
| DocVQA      | VQA on real documents             | 50k+   | English  | [ğŸ“„](https://arxiv.org/abs/2007.00398), [ğŸ”—](https://docvqa.org/) |
| InfographicVQA| VQA on infographic-style images | 5k+    | English  | [ğŸ“„](https://arxiv.org/abs/2206.01091), [ğŸ”—](https://github.com/google-research-datasets/infographicVQA) |
| VisualMRC   | Multimodal long-doc QA            | 12k    | English  | [ğŸ“„](https://arxiv.org/abs/2311.04180), [ğŸ”—](https://github.com/hpanwar08/VisualMRC) |

---

### ğŸŒ 5. Multilingual Document Understanding

| Dataset     | Description                       | Language | Paper / Link | ğŸ› ï¸ In Script? |
|-------------|-----------------------------------|----------|----------------|----------|
| XFUND       | Form understanding (7 languages)  | 7 langs  | [ğŸ“„](https://arxiv.org/abs/2102.08903), [ğŸ”—](https://github.com/doc-analysis/XFUND) |
| MLDoc       | Multilingual classification       | 8 langs  | [ğŸ“„](https://arxiv.org/abs/1811.00218), [ğŸ”—](https://github.com/facebookresearch/MLDoc) |

---

### ğŸ“Œ 6. Domain-Specific Document Datasets

| Dataset        | Domain     | Description                         | Language | Paper / Link | ğŸ› ï¸ In Script? |
|----------------|------------|-------------------------------------|----------|----------------|----------|
| Kleister-NDA   | Legal      | NDA entity extraction               | English  | [ğŸ“„](https://arxiv.org/abs/2003.04988), [ğŸ”—](https://github.com/applicaai/kleister-nda) |
| SciDocs        | Academic   | Citation prediction and doc linkage| English  | [ğŸ“„](https://arxiv.org/abs/2004.07180), [ğŸ”—](https://github.com/allenai/scidocs) |
| EU-LEGIS       | Legal      | Multilingual EU legal documents     | Multi    | [ğŸ“„](https://arxiv.org/abs/2305.15386), [ğŸ”—](https://huggingface.co/datasets/ferretj/eulegis) |

---

## ğŸ“¥ Download All Datasets with One Command

This project provides a script to automatically download datasets listed above.

### ğŸ”§ Usage Examples

```bash
# Download all datasets
python scripts/download_all.py

# Download a single dataset (e.g., FUNSD)
python scripts/download_all.py --only funsd

# List all available dataset keys
python scripts/download_all.py --list
```

### ğŸ“„ Config file

The script reads from scripts/datasets_config.json, which contains download URLs, formats (zip / tar.gz), and target folders.

#### ğŸ§© Example entry in config:

```
"funsd": {
  "name": "FUNSD",
  "url": "https://guillaumejaume.github.io/FUNSD/dataset.zip",
  "filetype": "zip",
  "target_dir": "funsd"
}
```

---

## ğŸ™Œ Contributing

Have a dataset we missed? Feel free to open a pull request or issue!

Please follow the format in `datasets_config.json` and include:
- Dataset name
- Task type
- URL
- Paper link (if available)
- License info

---

## ğŸ“œ License

This project is under the MIT License, but datasets themselves may have different licenses. Please refer to individual dataset links for license terms.
